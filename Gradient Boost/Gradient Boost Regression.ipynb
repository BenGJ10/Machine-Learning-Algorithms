{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09dc3d8d-79ec-4581-bc0e-1889264a4588",
   "metadata": {},
   "source": [
    "## Gradient Boost Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9a4d45-c72b-4715-9599-1dd150ef03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00dc9ad7-6abe-4108-a9d9-86d745020faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cardekho_imputated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27314e3-8ab8-4baf-b622-82d14dfa82b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>car_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Maruti Alto</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>120000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>19.70</td>\n",
       "      <td>796</td>\n",
       "      <td>46.30</td>\n",
       "      <td>5</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hyundai Grand</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Grand</td>\n",
       "      <td>5</td>\n",
       "      <td>20000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1197</td>\n",
       "      <td>82.00</td>\n",
       "      <td>5</td>\n",
       "      <td>550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hyundai i20</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>i20</td>\n",
       "      <td>11</td>\n",
       "      <td>60000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1197</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Maruti Alto</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>37000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>20.92</td>\n",
       "      <td>998</td>\n",
       "      <td>67.10</td>\n",
       "      <td>5</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ford Ecosport</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Ecosport</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>22.77</td>\n",
       "      <td>1498</td>\n",
       "      <td>98.59</td>\n",
       "      <td>5</td>\n",
       "      <td>570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       car_name    brand     model  vehicle_age  km_driven  \\\n",
       "0           0    Maruti Alto   Maruti      Alto            9     120000   \n",
       "1           1  Hyundai Grand  Hyundai     Grand            5      20000   \n",
       "2           2    Hyundai i20  Hyundai       i20           11      60000   \n",
       "3           3    Maruti Alto   Maruti      Alto            9      37000   \n",
       "4           4  Ford Ecosport     Ford  Ecosport            6      30000   \n",
       "\n",
       "  seller_type fuel_type transmission_type  mileage  engine  max_power  seats  \\\n",
       "0  Individual    Petrol            Manual    19.70     796      46.30      5   \n",
       "1  Individual    Petrol            Manual    18.90    1197      82.00      5   \n",
       "2  Individual    Petrol            Manual    17.00    1197      80.00      5   \n",
       "3  Individual    Petrol            Manual    20.92     998      67.10      5   \n",
       "4      Dealer    Diesel            Manual    22.77    1498      98.59      5   \n",
       "\n",
       "   selling_price  \n",
       "0         120000  \n",
       "1         550000  \n",
       "2         215000  \n",
       "3         226000  \n",
       "4         570000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb1a40c-2165-4578-8abe-878d1089bfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15411, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8888e1-b194-43d2-aacf-cc9375092886",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fadf108-a048-4f83-9932-9767c1878d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "car_name             0\n",
       "brand                0\n",
       "model                0\n",
       "vehicle_age          0\n",
       "km_driven            0\n",
       "seller_type          0\n",
       "fuel_type            0\n",
       "transmission_type    0\n",
       "mileage              0\n",
       "engine               0\n",
       "max_power            0\n",
       "seats                0\n",
       "selling_price        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52b1ac6-22cc-45af-8dd3-4046c4f907a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping car_name and brand as model is the only required one\n",
    "df.drop(columns = ['car_name', 'brand'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3fede1-a7df-4977-bcf2-327ae12e58c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Numerical Features:  8\n",
      "Num of Categorical Features:  4\n"
     ]
    }
   ],
   "source": [
    "# Getting All Different Types OF Features\n",
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "print('Num of Numerical Features: ', len(num_features))\n",
    "\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print('Num of Categorical Features: ', len(cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bd862d-bcba-4955-a060-c7d23cc72839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent and Dependent features\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['selling_price'], axis = 1)\n",
    "Y = df['selling_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb47e6-3751-4f59-9dc3-89808a2f33ff",
   "metadata": {},
   "source": [
    "## Feature Encoding and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89afb52-ba88-4cff-8ba6-8b6ff4f6c451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['model'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ebf060f-0ee7-4755-94c9-d2bb2dfa2ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "i20            906\n",
       "Swift Dzire    890\n",
       "Swift          781\n",
       "Alto           778\n",
       "City           757\n",
       "              ... \n",
       "Ghibli           1\n",
       "Altroz           1\n",
       "GTC4Lusso        1\n",
       "Aura             1\n",
       "Gurkha           1\n",
       "Name: count, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14eb1757-26cc-49de-97d7-abf52e1effa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a3aeb1-1921-49b0-917e-27a98b9139e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['model'] = le.fit_transform(X['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf960cb8-cbd1-44ca-aff9-36faab702739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "numerical_features = X.select_dtypes(exclude = 'object').columns\n",
    "onehot_columns = ['seller_type','fuel_type','transmission_type']\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop = 'first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, onehot_columns),\n",
    "        (\"StandardScaler\", numeric_transformer, numerical_features)\n",
    "        \n",
    "    ],remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "809950ec-04ee-4176-a85e-fa072c5cbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b02fb2a1-de1a-4a27-940c-6cc0a733c2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.738694</td>\n",
       "      <td>-1.519714</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>1.247335</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-1.324259</td>\n",
       "      <td>-1.263352</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.738516</td>\n",
       "      <td>-0.225693</td>\n",
       "      <td>-0.343933</td>\n",
       "      <td>-0.690016</td>\n",
       "      <td>-0.192071</td>\n",
       "      <td>-0.554718</td>\n",
       "      <td>-0.432571</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.738339</td>\n",
       "      <td>1.536377</td>\n",
       "      <td>1.647309</td>\n",
       "      <td>0.084924</td>\n",
       "      <td>-0.647583</td>\n",
       "      <td>-0.554718</td>\n",
       "      <td>-0.479113</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.738162</td>\n",
       "      <td>-1.519714</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>-0.360667</td>\n",
       "      <td>0.292211</td>\n",
       "      <td>-0.936610</td>\n",
       "      <td>-0.779312</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.737985</td>\n",
       "      <td>-0.666211</td>\n",
       "      <td>-0.012060</td>\n",
       "      <td>-0.496281</td>\n",
       "      <td>0.735736</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>-0.046502</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15406</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.723327</td>\n",
       "      <td>1.508844</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>-0.869744</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>-0.767733</td>\n",
       "      <td>-0.757204</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15407</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.723859</td>\n",
       "      <td>-0.556082</td>\n",
       "      <td>-1.339555</td>\n",
       "      <td>-0.728763</td>\n",
       "      <td>-0.527711</td>\n",
       "      <td>-0.216964</td>\n",
       "      <td>-0.220803</td>\n",
       "      <td>2.073444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.724036</td>\n",
       "      <td>0.407551</td>\n",
       "      <td>-0.012060</td>\n",
       "      <td>0.220539</td>\n",
       "      <td>0.344954</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.068225</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15409</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.724213</td>\n",
       "      <td>1.426247</td>\n",
       "      <td>-0.343933</td>\n",
       "      <td>72.541850</td>\n",
       "      <td>-0.887326</td>\n",
       "      <td>1.329794</td>\n",
       "      <td>0.917158</td>\n",
       "      <td>2.073444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15410</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.724391</td>\n",
       "      <td>-1.024131</td>\n",
       "      <td>-1.339555</td>\n",
       "      <td>-0.825631</td>\n",
       "      <td>-0.407839</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.395884</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15411 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6         7         8         9   \\\n",
       "0      1.0  0.0  0.0  0.0  0.0  1.0  1.0 -1.738694 -1.519714  0.983562   \n",
       "1      1.0  0.0  0.0  0.0  0.0  1.0  1.0 -1.738516 -0.225693 -0.343933   \n",
       "2      1.0  0.0  0.0  0.0  0.0  1.0  1.0 -1.738339  1.536377  1.647309   \n",
       "3      1.0  0.0  0.0  0.0  0.0  1.0  1.0 -1.738162 -1.519714  0.983562   \n",
       "4      0.0  0.0  1.0  0.0  0.0  0.0  1.0 -1.737985 -0.666211 -0.012060   \n",
       "...    ...  ...  ...  ...  ...  ...  ...       ...       ...       ...   \n",
       "15406  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.723327  1.508844  0.983562   \n",
       "15407  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.723859 -0.556082 -1.339555   \n",
       "15408  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.724036  0.407551 -0.012060   \n",
       "15409  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.724213  1.426247 -0.343933   \n",
       "15410  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.724391 -1.024131 -1.339555   \n",
       "\n",
       "              10        11        12        13        14  \n",
       "0       1.247335 -0.000276 -1.324259 -1.263352 -0.403022  \n",
       "1      -0.690016 -0.192071 -0.554718 -0.432571 -0.403022  \n",
       "2       0.084924 -0.647583 -0.554718 -0.479113 -0.403022  \n",
       "3      -0.360667  0.292211 -0.936610 -0.779312 -0.403022  \n",
       "4      -0.496281  0.735736  0.022918 -0.046502 -0.403022  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "15406  -0.869744  0.026096 -0.767733 -0.757204 -0.403022  \n",
       "15407  -0.728763 -0.527711 -0.216964 -0.220803  2.073444  \n",
       "15408   0.220539  0.344954  0.022918  0.068225 -0.403022  \n",
       "15409  72.541850 -0.887326  1.329794  0.917158  2.073444  \n",
       "15410  -0.825631 -0.407839  0.020999  0.395884 -0.403022  \n",
       "\n",
       "[15411 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36bcb9b1-9303-4300-972a-abe0a4751c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12328, 15), (3083, 15))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate dataset into train and test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05cfaaf-c637-4a8d-9d95-90dd0b19f7f5",
   "metadata": {},
   "source": [
    "## Model Training And Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebdebacd-2617-4f0e-9d4a-0dbe96bee3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60b2b960-ec5b-4ef7-b786-ebe82624522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Function to Evaluate Model\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2209f8e8-f59a-407a-b5e7-c1f4b2dae3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553850.0494\n",
      "- Mean Absolute Error: 268104.1303\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502582.0834\n",
      "- Mean Absolute Error: 279686.6479\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553850.0538\n",
      "- Mean Absolute Error: 268101.7491\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502581.1494\n",
      "- Mean Absolute Error: 279682.7929\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553850.6941\n",
      "- Mean Absolute Error: 268061.4421\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502572.3576\n",
      "- Mean Absolute Error: 279625.1576\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 335460.8145\n",
      "- Mean Absolute Error: 96905.2401\n",
      "- R2 Score: 0.8612\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 302364.2710\n",
      "- Mean Absolute Error: 124343.6669\n",
      "- R2 Score: 0.8786\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 330400.0785\n",
      "- Mean Absolute Error: 129504.9870\n",
      "- R2 Score: 0.8550\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 123392.9172\n",
      "- Mean Absolute Error: 36237.6046\n",
      "- R2 Score: 0.9812\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 234687.6231\n",
      "- Mean Absolute Error: 98163.4009\n",
      "- R2 Score: 0.9268\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 203893.5638\n",
      "- Mean Absolute Error: 110153.5965\n",
      "- R2 Score: 0.9487\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 263687.5920\n",
      "- Mean Absolute Error: 126541.0625\n",
      "- R2 Score: 0.9076\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Beginning Model Training\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"Gradient Boost Regressor\": GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, Y_train) # Training the model\n",
    "\n",
    "    # Making predictions\n",
    "    Y_train_pred = model.predict(X_train)\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluateing Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(Y_train, Y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(Y_test, Y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    print('=' * 35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac09f50-bc9e-476e-bf39-df6a9f6744b9",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da2b9d1-12d0-4c76-8569-f1fff61e593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize few parameter for Hyperparamter tuning\n",
    "\n",
    "\n",
    "rf_params = {\"max_depth\": [5, 8, 15, None, 10],\n",
    "             \"max_features\": [5, 7, \"auto\", 8],\n",
    "             \"min_samples_split\": [2, 8, 15, 20],\n",
    "             \"n_estimators\": [100, 200, 500, 1000]}\n",
    "\n",
    "gradient_params = {\"loss\": ['squared_error', 'huber', 'absolute_error'],\n",
    "                \"criterion\": ['friedman_mse', 'squared_error', 'mse'],\n",
    "                \"min_samples_split\": [2, 8, 15, 20],\n",
    "                \"n_estimators\": [100, 200, 500],\n",
    "                \"max_depth\": [5, 8, 15, None, 10],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f009da50-c57b-4667-b3dd-0de86267b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models list for Hyperparameter tuning\n",
    "\n",
    "randomcv_models = [(\"RF\", RandomForestRegressor(), rf_params),\n",
    "                   (\"GradientBoost\", GradientBoostingRegressor(), gradient_params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a6b68f4-8457-4e96-b75b-1e211ca4700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=1000; total time=   6.3s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=500; total time=   4.9s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=500; total time=   7.7s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=2, n_estimators=500; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104d1dbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=8, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=1000; total time=   7.3s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=500; total time=   6.8s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=20, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=20, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=2, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=15, n_estimators=500; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106949bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=20, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=500; total time=   5.5s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=2, n_estimators=500; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1037d5bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=1000; total time=   7.4s\n",
      "[CV] END max_depth=None, max_features=7, min_samples_split=15, n_estimators=1000; total time=  11.6s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=200; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=20, n_estimators=500; total time=   4.3s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=500; total time=   5.3s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=20, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=20, n_estimators=1000; total time=   8.0s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=2, n_estimators=500; total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106339bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model, params \u001b[38;5;129;01min\u001b[39;00m randomcv_models:\n\u001b[1;32m      6\u001b[0m     random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator \u001b[38;5;241m=\u001b[39m model, param_distributions \u001b[38;5;241m=\u001b[39m params, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     random\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m      8\u001b[0m     model_param[name] \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_param:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1951\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1952\u001b[0m         ParameterSampler(\n\u001b[1;32m   1953\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m   1954\u001b[0m         )\n\u001b[1;32m   1955\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m         clone(base_estimator),\n\u001b[1;32m    973\u001b[0m         X,\n\u001b[1;32m    974\u001b[0m         y,\n\u001b[1;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    981\u001b[0m     )\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    986\u001b[0m )\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model_param = {}\n",
    "\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator = model, param_distributions = params, n_iter = 100, cv = 3, verbose = 2, n_jobs = -1)\n",
    "    random.fit(X_train, Y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "336bf218-cf93-4bc3-933e-2d8e192ab1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 131011.9921\n",
      "- Mean Absolute Error: 49824.7443\n",
      "- R2 Score: 0.9788\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 219243.0636\n",
      "- Mean Absolute Error: 96044.4336\n",
      "- R2 Score: 0.9361\n",
      "===================================\n",
      "\n",
      "\n",
      "GradientBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 58721.7064\n",
      "- Mean Absolute Error: 28099.4391\n",
      "- R2 Score: 0.9957\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 212040.3658\n",
      "- Mean Absolute Error: 93339.0072\n",
      "- R2 Score: 0.9403\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retraining the models with best parameters\n",
    "models = {\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators = 500, min_samples_split = 2, max_features = 8, max_depth = 15, n_jobs = -1),\n",
    "    \"GradientBoost Regressor\":GradientBoostingRegressor(n_estimators = 200,\n",
    "                                                         min_samples_split = 8, max_depth = 10, loss = 'huber', criterion = 'friedman_mse')\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, Y_train) # Training the model\n",
    "\n",
    "    # Making predictions\n",
    "    Y_train_pred = model.predict(X_train)\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluateing Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(Y_train, Y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(Y_test, Y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    print('=' * 35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb6bb2-a174-404e-9ce8-c25485d4d739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
